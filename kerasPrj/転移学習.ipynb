{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 転移学習（Transfer Learning）\n",
    "学習済みのネットワークを別のタスクに応用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tunning\n",
    "学習済みのネットワークの出力層に近い箇所のみ再学習する。\n",
    "\n",
    "## 例\n",
    "[1]では、imageNetで1000個クラス分類を学習したvgg16をFineTunningすることで、イヌ／ネコの２クラス分類タスクで正解率96%を達成している。（画像水増しあり）\n",
    "以下は該当箇所の抜粋。テスト正解率を計算したところ97%だった。\n",
    "\n",
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "IMG_DIM = (150, 150)\n",
    "\n",
    "train_files = glob.glob('training_data/*')\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in train_files]\n",
    "\n",
    "validation_files = glob.glob('validation_data/*')\n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
    "validation_imgs = np.array(validation_imgs)\n",
    "validation_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in validation_files]\n",
    "\n",
    "print('Train dataset shape:', train_imgs.shape,\n",
    "      '\\tValidation dataset shape:', validation_imgs.shape)\n",
    "\n",
    "# rescale img\n",
    "train_imgs_scaled = train_imgs.astype('float32')\n",
    "validation_imgs_scaled  = validation_imgs.astype('float32')\n",
    "train_imgs_scaled /= 255\n",
    "validation_imgs_scaled /= 255\n",
    "\n",
    "print(train_imgs[0].shape)\n",
    "array_to_img(train_imgs[0])\n",
    "\n",
    "# make numeric labels\n",
    "batch_size = 30\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "input_shape = (150, 150, 3)\n",
    "\n",
    "# encode text category labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "validation_labels_enc = le.transform(validation_labels)\n",
    "\n",
    "print(train_labels[1495:1505], train_labels_enc[1495:1505])\n",
    "\n",
    "# img Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
    "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,\n",
    "                                   horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)\n",
    "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)\n",
    "\n",
    "# load VGG16\n",
    "from keras.applications import vgg16\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet',\n",
    "                  input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "\n",
    "vgg_model.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    if layer.name in ['block5_conv1', 'block4_conv1']:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
    "print(pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']))\n",
    "\n",
    "bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1])\n",
    "print(bottleneck_feature_example.shape)\n",
    "plt.imshow(bottleneck_feature_example[0][:,:,0])\n",
    "\n",
    "def get_bottleneck_features(model, input_imgs):\n",
    "    features = model.predict(input_imgs, verbose=0)\n",
    "    return features\n",
    "\n",
    "train_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)\n",
    "validation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)\n",
    "\n",
    "print('Train Bottleneck Features:', train_features_vgg.shape,\n",
    "      '\\tValidation Bottleneck Features:', validation_features_vgg.shape)\n",
    "\n",
    "# simple CNN\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,\n",
    "                              validation_data=val_generator, validation_steps=50,\n",
    "                              verbose=1)\n",
    "\n",
    "# model.save('cats_dogs_tlearn_img_aug_cnn.h5')\n",
    "\n",
    "# results\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,101))\n",
    "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, 31, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, 31, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('simpleCNN_vgg16fineTune_dataAug.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Test dataset shape: (1000, 150, 150, 3)\n",
      "['cat', 'cat', 'cat', 'cat', 'cat'] [0, 0, 0, 0, 0]\n",
      "[0 0 0 0 0]\n",
      "[0 1 0 0 0]\n",
      "Test Acc:   0.971\n"
     ]
    }
   ],
   "source": [
    "# load dependencies\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.models import load_model\n",
    "\n",
    "# load saved models\n",
    "tl_img_aug_finetune_cnn = load_model('cats_dogs_tlearn_finetune_img_aug_cnn.h5')\n",
    "\n",
    "# load other configurations\n",
    "IMG_DIM = (150, 150)\n",
    "input_shape = (150, 150, 3)\n",
    "num2class_label_transformer = lambda l: ['cat' if x == 0 else 'dog' for x in l]\n",
    "class2num_label_transformer = lambda l: [0 if x == 'cat' else 1 for x in l]\n",
    "\n",
    "# load VGG model for bottleneck features\n",
    "from keras.applications import vgg16\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet',\n",
    "                  input_shape=input_shape)\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "vgg_model.trainable = False\n",
    "\n",
    "def get_bottleneck_features(model, input_imgs):\n",
    "    features = model.predict(input_imgs, verbose=0)\n",
    "    return features\n",
    "\n",
    "\n",
    "IMG_DIM = (150, 150)\n",
    "\n",
    "test_files = glob.glob('test_data/*')\n",
    "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]\n",
    "test_imgs = np.array(test_imgs)\n",
    "test_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in test_files]\n",
    "\n",
    "test_imgs_scaled = test_imgs.astype('float32')\n",
    "test_imgs_scaled /= 255\n",
    "test_labels_enc = class2num_label_transformer(test_labels)\n",
    "\n",
    "\n",
    "print('Test dataset shape:', test_imgs.shape)\n",
    "print(test_labels[0:5], test_labels_enc[0:5])\n",
    "\n",
    "test_labels_enc_np = np.array(test_labels_enc)\n",
    "print(test_labels_enc_np[0:5])\n",
    "\n",
    "predictions = tl_img_aug_finetune_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
    "predictions = predictions[:,0]\n",
    "print(predictions[0:5])\n",
    "test_acc = (np.sum(test_labels_enc_np == predictions)/len(predictions))\n",
    "print('Test Acc: %7.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "[1]A Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning, https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
